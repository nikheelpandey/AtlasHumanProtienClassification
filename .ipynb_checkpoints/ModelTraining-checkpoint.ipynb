{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original version of this kernel is hosted [on kaggle](https://www.kaggle.com/nikhilpandey360/fork-of-rgby-adam-sigmoid-500-10-ep-10-inception) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model,Model\n",
    "from keras.layers import Activation,Dropout,Flatten,Dense,Input,BatchNormalization,Conv2D\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import Callback\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ac5cedba5491fbe1b43241d61ec1bdd7a61c62fb"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/train.csv\")\n",
    "print(\"Total number of unique ids:\",df.Id.count())\n",
    "print(\"Total number of images:\", df.Id.count()*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "40e9cf83ac3d6d3dfd48ee036fa5dfba97cae8af"
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c100980a6cf331feb702d6c9b217cd7c254671aa"
   },
   "source": [
    "Let's train a classifier for baseline. I'm choosing InceptionResnet50 but another interesting candidate could be a smaller ResNet34. Anyway, it is just a base line classifier so I am not expecting a great metric coming as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8a46f740b05574d55f5d48fd636d500ae14b7e6"
   },
   "outputs": [],
   "source": [
    "path_to_train = '/kaggle/input/train/'\n",
    "data = pd.read_csv('/kaggle/input/train.csv')\n",
    "\n",
    "train_dataset_info = []\n",
    "# split the labels and make a numpy array out of it\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)\n",
    "\n",
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, test_ids, train_targets, test_target = train_test_split(\n",
    "    data['Id'], data['Target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom Data Generator \n",
    "The image data generator provided in keras is great to work when we take care of the labels in pre-processing. However, in the following cell, we are generating correct label for the batch while training the model.\n",
    "\n",
    "### Image contruction and its repercussions\n",
    "\n",
    "I have constructed an image from 4 different filters by treating R and G filter images as a channel of their own but for have created the third channel by averaging the Blue and Yellow filter. \n",
    "\n",
    "The reason for doing so is that beacuse I have decided to used keras to implement transfer learning, the default input to the base model is a 3 channel image. To use 4 channel image, we need to modify the input layer of the pretrained model. As of writing this kernel, I haven't found a proper way of doing so in keras although it is possible to do the same in fast.ai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "997e0cfd24fde6ab5ba9ebb7ef881fbc9a0a07d6"
   },
   "outputs": [],
   "source": [
    "class data_generator:\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        while True:\n",
    "            random_indexes = np.random.choice(len(dataset_info), batch_size)\n",
    "            batch_images = np.empty((batch_size, shape[0], shape[1], shape[2]))\n",
    "            batch_labels = np.zeros((batch_size, 28))\n",
    "            for i, idx in enumerate(random_indexes):\n",
    "                image = data_generator.load_image(\n",
    "                    dataset_info[idx]['path'], shape)   \n",
    "                if augument:\n",
    "                    image = data_generator.augment(image)\n",
    "                batch_images[i] = image\n",
    "                batch_labels[i][dataset_info[idx]['labels']] = 1\n",
    "            yield batch_images, batch_labels\n",
    "    \n",
    "         \n",
    "    def load_image(path, shape):\n",
    "        R = np.array(Image.open(path+'_red.png'))\n",
    "        G = np.array(Image.open(path+'_green.png'))\n",
    "        B = np.array(Image.open(path+'_blue.png'))\n",
    "        Y = np.array(Image.open(path+'_yellow.png'))\n",
    "\n",
    "        image = np.stack((\n",
    "            R,\n",
    "            G, \n",
    "            (B+Y)/2),-1)\n",
    "\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        image = np.divide(image, 255)\n",
    "        return image        \n",
    "    \n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "        \n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a4add9fa7daf95f5880d82fafdb43c053d96977"
   },
   "outputs": [],
   "source": [
    "input_shape=(299,299,3)\n",
    "train_datagen = data_generator.create_train(\n",
    "    train_dataset_info, 5, input_shape, augument=True)\n",
    "\n",
    "images, labels = next(train_datagen)\n",
    "\n",
    "fig, ax = plt.subplots(1,5,figsize=(25,5))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(images[i])\n",
    "print('min: {0}, max: {1}'.format(images.min(), images.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation \n",
    "\n",
    "Get the InceptionResNetV2. I have added a new base layer to the model. Since it is a multilabel classification, it is required that we don't use softmax as output. Sigmoid is useful as long as we are using categorical cross entropy as a loss function.\n",
    "\n",
    "A great point to be noted is that perhaps latest loss function like focal loss and BCE outperform the conventional loss function in case of class imbalance which wat often the case than not. Refer to [this paper explaining the idea](https://arxiv.org/pdf/1708.02002.pdf) in detail. My tensorflow implementation will also address this issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1598f679d67f3668f44b5493a0e0ac45b0ffbe80"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    model = Sequential()\n",
    "    model.add(InceptionResNetV2(include_top=False,input_shape= input_shape, pooling='avg', weights=\"imagenet\"))\n",
    "    model.add(Dense(1200))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(n_out, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4bfda06a1c00c0387e5fa16b628239e81571683e"
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "def show_history(history):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('f1')\n",
    "    ax[1].plot(history.epoch, history.history[\"f1\"], label=\"Train f1\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_f1\"], label=\"Validation f1\")\n",
    "    ax[2].set_title('acc')\n",
    "    ax[2].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n",
    "    ax[2].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[2].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d71acd73dc9f5c4605f943485b7a3d8887832736",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    input_shape, \n",
    "    n_out=28)\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    '/kaggle/working/InceptionResNetV2.model',\n",
    "    verbose=2, save_best_only=True)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "INPUT_SHAPE = (299,299,3)\n",
    "\n",
    "train_generator = data_generator.create_train(\n",
    "    train_dataset_info[train_ids.index], BATCH_SIZE, INPUT_SHAPE, augument=False)\n",
    "validation_generator = data_generator.create_train(\n",
    "    train_dataset_info[test_ids.index], 256, INPUT_SHAPE, augument=False)\n",
    "\n",
    "model.layers[0].trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',  \n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=['acc', f1])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=500,\n",
    "    validation_data=next(validation_generator),\n",
    "    epochs=30, \n",
    "    verbose=1,\n",
    "    callbacks=[checkpointer])\n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Submission on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cb9ffd60a64a96596ca132728653f00efd0c64c"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "submit = pd.read_csv('../input/sample_submission.csv')\n",
    "predicted = []\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../input/test/', name)\n",
    "    image = data_generator.load_image(path, INPUT_SHAPE)\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    label_predict = np.arange(28)[score_predict>=0.1]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "    \n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
